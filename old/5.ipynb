{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия — Notebook для `Doctor.xlsx`\n",
    "\n",
    "Задачи:\n",
    "- Описательная статистика (`summary`), создание категориальных факторов при необходимости;\n",
    "- Базовая логит-модель (`glm` с биномиальной семьёй), уравнение регрессии;\n",
    "- Тесты значимости коэффициентов (Wald / z), тест значимости модели (Likelihood Ratio и Wald);\n",
    "- Доверительные интервалы (confint и вручную), сравнение Logit vs Probit;\n",
    "- Confusion matrix (порог 0.5), sensitivity / specificity, поиск оптимального порога (Youden index);\n",
    "- (Опционально) разбиение на train/test, ROC-кривая и AUC;\n",
    "- Stepwise selection по AIC (stepAIC аналог)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_theme(style='whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных и предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctorDataFrame = pd.read_excel('../datasets/Doctor.xlsx')\n",
    "display(doctorDataFrame.head())\n",
    "\n",
    "def toFloatFromCommaSafe(x):\n",
    "    try:\n",
    "        if pd.isna(x):\n",
    "            return np.nan\n",
    "        s = str(x).strip().replace(',', '.')\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "for col in doctorDataFrame.columns:\n",
    "    if col != 'y':\n",
    "        doctorDataFrame[col] = doctorDataFrame[col].apply(toFloatFromCommaSafe)\n",
    "\n",
    "doctorDataFrame['y'] = doctorDataFrame['y'].astype(int)\n",
    "\n",
    "print('Размер данных:', doctorDataFrame.shape)\n",
    "doctorDataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Описательная статистика (`summary`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(doctorDataFrame.describe(include='all'))\n",
    "\n",
    "print('\\nCounts of y:')\n",
    "print(doctorDataFrame['y'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Создание категориальной переменной (factor)\n",
    "\n",
    "Если какая-то переменная (например, x4) должна быть фактором (категориальной), конвертируем её в `category` и при необходимости создаём дамми-переменные.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctorDataFrame['x4_cat'] = doctorDataFrame['x4'].astype('category')\n",
    "print('x4 unique categories:', doctorDataFrame['x4_cat'].cat.categories)\n",
    "display(doctorDataFrame[['x4','x4_cat']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Базовая логит-модель (glm с биномиальной семьёй)\n",
    "\n",
    "Модель с максимально возможным количеством предикторов (включая категориальные через C())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сформируем формулу: y ~ x1 + x2 + x3 + x5 + x4_cat\n",
    "predictorTerms = []\n",
    "for col in ['x1','x2','x3','x5']:\n",
    "    if col in doctorDataFrame.columns:\n",
    "        predictorTerms.append(col)\n",
    "predictorTerms.append('C(x4_cat)')\n",
    "\n",
    "formula = 'y ~ ' + ' + '.join(predictorTerms)\n",
    "print('Formula:', formula)\n",
    "\n",
    "# Fit GLM (Binomial = logistic)\n",
    "glmLogitModel = smf.glm(formula=formula, data=doctorDataFrame, family=sm.families.Binomial()).fit()\n",
    "print('--- GLM (Logit) summary ---')\n",
    "print(glmLogitModel.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Уравнение бинарной регрессии (логит)\n",
    "Запишем в явном виде logit(p) = beta0 + beta1*x1 + ... и покажем коэффициенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficientsLogit = glmLogitModel.params\n",
    "print('Coefficients (logit):')\n",
    "display(coefficientsLogit)\n",
    "\n",
    "interceptLogit = coefficientsLogit.get('Intercept', coefficientsLogit.get('const', None))\n",
    "termsLogit = []\n",
    "for name, coef in coefficientsLogit.items():\n",
    "    termsLogit.append(f'({coef:.4f})*{name}')\n",
    "equationLogit = 'logit(p) = ' + ' + '.join(termsLogit)\n",
    "print('\\nRegression equation (logit scale):')\n",
    "print(equationLogit)\n",
    "print('\\nProbability form: p = 1 / (1 + exp(-linear_predictor))')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Тест значимости коэффициентов по отдельности (Wald / z-test)\n",
    "\n",
    "Для GLM стандартный вывод содержит `z` (Wald) и p-values; выведем статистики явно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefEstimate = glmLogitModel.params\n",
    "coefStdErr = glmLogitModel.bse\n",
    "zValues = coefEstimate / coefStdErr\n",
    "pValues = 2 * (1 - sps.norm.cdf(np.abs(zValues)))\n",
    "\n",
    "resultTable = pd.DataFrame({\n",
    "    'coef': coefEstimate,\n",
    "    'stdErr': coefStdErr,\n",
    "    'z': zValues,\n",
    "    'pValue': pValues\n",
    "})\n",
    "print('Wald z-test for coefficients:')\n",
    "display(resultTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11506e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffIndex = glmLogitModel.params.index.tolist()\n",
    "numCoeffs = len(coeffIndex)\n",
    "\n",
    "waldResults = []\n",
    "for i, coefName in enumerate(coeffIndex):\n",
    "    # R матрица (1 x k): тест H0: beta_i = 0\n",
    "    R = np.zeros((1, numCoeffs))\n",
    "    R[0, i] = 1.0\n",
    "\n",
    "    waldRes = glmLogitModel.wald_test(R, scalar=True)\n",
    "    statRaw = waldRes.statistic\n",
    "    waldStat = float(np.atleast_1d(statRaw).squeeze())\n",
    "    waldPvalue = float(waldRes.pvalue)\n",
    "    \n",
    "\n",
    "    waldResults.append({\n",
    "        'term': coefName,\n",
    "        'waldStat_chi2': waldStat,\n",
    "        'df': 1,\n",
    "        'pValue': waldPvalue\n",
    "    })\n",
    "\n",
    "waldResultsDf = pd.DataFrame(waldResults).set_index('term')\n",
    "print('Wald test (each coefficient separately):')\n",
    "display(waldResultsDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Значимость регрессии в целом\n",
    "\n",
    "Проверим модель в целом двумя способами:\n",
    "- Wald test (в статистическом summary есть);  \n",
    "- Likelihood Ratio Test: сравним модель с нулевой моделью (intercept-only).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all coefficients = 0 (включая intercept обычно; при желании можно исключить const)\n",
    "allR = np.eye(numCoeffs)\n",
    "waldResAll = glmLogitModel.wald_test(allR, scalar=True)\n",
    "\n",
    "statAllRaw = waldResAll.statistic\n",
    "waldStatAll = float(np.atleast_1d(statAllRaw).squeeze())\n",
    "dfAll = allR.shape[0]\n",
    "waldPvalueAll = float(waldResAll.pvalue)\n",
    "print('Wald test (all coefficients simultaneously):')\n",
    "print(f'Chi2 stat = {waldStatAll:.6f}, df = {dfAll}, p-value = {waldPvalueAll:.6g}')\n",
    "\n",
    "\n",
    "# Wald statistic (в statsmodels есть поле 'deviance' и 'null_deviance') — можно посмотреть deviance reduction\n",
    "nullDeviance = glmLogitModel.null_deviance\n",
    "modelDeviance = glmLogitModel.deviance\n",
    "devianceDiff = nullDeviance - modelDeviance\n",
    "dfDiff = glmLogitModel.df_model\n",
    "pValueDeviance = 1 - sps.chi2.cdf(devianceDiff, dfDiff)\n",
    "print('\\nDeviance null =', nullDeviance)\n",
    "print('Deviance model =', modelDeviance)\n",
    "print('Deviance reduction =', devianceDiff, ', df =', dfDiff, ', p-value =', pValueDeviance)\n",
    "\n",
    "# LR test explicitly: compare log-likelihoods with intercept-only model\n",
    "yVec = doctorDataFrame['y']\n",
    "XIntercept = sm.add_constant(pd.DataFrame({'const': np.ones(len(doctorDataFrame))}))\n",
    "nullModel = sm.GLM(yVec, XIntercept, family=sm.families.Binomial()).fit()\n",
    "llfReduced = nullModel.llf\n",
    "llfFull = glmLogitModel.llf\n",
    "lrStat = 2 * (llfFull - llfReduced)\n",
    "lrDf = glmLogitModel.df_model\n",
    "lrPvalue = 1 - sps.chi2.cdf(lrStat, lrDf)\n",
    "print(f'\\nLLF full  = {llfFull:.6f}')\n",
    "print(f'LLF null  = {llfReduced:.6f}')\n",
    "print(f'LR stat   = {lrStat:.6f}')\n",
    "print(f'df diff   = {dfDiff}')\n",
    "print(f'LR p-value= {lrPvalue:.6e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Доверительные интервалы для коэффициентов регрессии\n",
    "\n",
    "- `confint()` — стандартные (Wald) интервалы из statsmodels;  \n",
    "- `confint_default` — построим вручную как coef ± z*se (обычно совпадает с confint для GLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciWald = glmLogitModel.conf_int(alpha=0.05)\n",
    "ciWald.columns = ['ciLower','ciUpper']\n",
    "ciManualLower = coefEstimate - 1.96 * coefStdErr\n",
    "ciManualUpper = coefEstimate + 1.96 * coefStdErr\n",
    "ciManual = pd.DataFrame({'ciManualLower': ciManualLower, 'ciManualUpper': ciManualUpper})\n",
    "print('confint (Wald) from model:')\n",
    "display(ciWald)\n",
    "print('\\nManual approx (coef ± 1.96*se):')\n",
    "display(ciManual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сравнение Logit vs Probit\n",
    "\n",
    "Построим Probit (GLM с link=probit) и сравним AIC / логарифмы правдоподобия / прогнозы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmProbitModel = smf.glm(formula=formula, data=doctorDataFrame, family=sm.families.Binomial(link=sm.families.links.Probit())).fit()\n",
    "print('--- Probit summary ---')\n",
    "print(glmProbitModel.summary())\n",
    "\n",
    "print('\\nComparison:')\n",
    "print('Logit AIC =', glmLogitModel.aic, ', Probit AIC =', glmProbitModel.aic)\n",
    "print('Logit llf =', glmLogitModel.llf, ', Probit llf =', glmProbitModel.llf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Confusion matrix при пороге 0.5, sensitivity и specificity\n",
    "\n",
    "Напишем вспомогательные функции для матрицы и метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrixFromPreds(yTrue, probPred, threshold=0.5):\n",
    "    yPred = (probPred >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(yTrue, yPred).ravel()\n",
    "    cmDf = pd.DataFrame([[tn, fp],[fn, tp]], index=['Actual0','Actual1'], columns=['Pred0','Pred1'])\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn)>0 else np.nan\n",
    "    specificity = tn / (tn + fp) if (tn + fp)>0 else np.nan\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return cmDf, sensitivity, specificity, accuracy\n",
    "\n",
    "probPredLogit = glmLogitModel.predict(doctorDataFrame)\n",
    "\n",
    "cm50, sens50, spec50, acc50 = confusionMatrixFromPreds(doctorDataFrame['y'].values, probPredLogit, threshold=0.5)\n",
    "print('Confusion matrix (threshold=0.5):')\n",
    "display(cm50)\n",
    "print('\\nSensitivity =', sens50, ', Specificity =', spec50, ', Accuracy =', acc50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Поиск оптимального порога (Youden index) и матрица для него\n",
    "\n",
    "Оптимальный порог — максимизирует (sensitivity + specificity - 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOptimalCutoff(yTrue, probPred):\n",
    "    fpr, tpr, thresholds = roc_curve(yTrue, probPred)\n",
    "    youdenIndex = tpr - fpr\n",
    "    bestIdx = np.argmax(youdenIndex)\n",
    "    bestThreshold = thresholds[bestIdx]\n",
    "    bestSens = tpr[bestIdx]\n",
    "    bestSpec = 1 - fpr[bestIdx]\n",
    "    return bestThreshold, bestSens, bestSpec, bestIdx\n",
    "\n",
    "bestThr, bestSens, bestSpec, bestIdx = findOptimalCutoff(doctorDataFrame['y'].values, probPredLogit)\n",
    "print('Optimal threshold (Youden) =', bestThr)\n",
    "print('Sensitivity =', bestSens, ', Specificity =', bestSpec)\n",
    "\n",
    "cmOptimal, sensOpt, specOpt, accOpt = confusionMatrixFromPreds(doctorDataFrame['y'].values, probPredLogit, threshold=bestThr)\n",
    "print('\\nConfusion matrix (optimal threshold):')\n",
    "display(cmOptimal)\n",
    "print('\\nAccuracy =', accOpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Разбиение выборки на train/test (опционально) и ROC кривая\n",
    "\n",
    "Если выборка большая, полезно оценивать модель на тестовой выборке. Здесь приведён пример с fraction = 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFrac = 0.7\n",
    "doctorTrain = doctorDataFrame.sample(frac=trainFrac, random_state=42)\n",
    "doctorTest = doctorDataFrame.drop(doctorTrain.index)\n",
    "print('Train size =', len(doctorTrain), ', Test size =', len(doctorTest))\n",
    "\n",
    "glmLogitTrain = smf.glm(formula=formula, data=doctorTrain, family=sm.families.Binomial()).fit()\n",
    "probPredTest = glmLogitTrain.predict(doctorTest)\n",
    "fpr, tpr, thresholds = roc_curve(doctorTest['y'], probPredTest)\n",
    "aucScore = roc_auc_score(doctorTest['y'], probPredTest)\n",
    "print('Test AUC =', aucScore)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC = {aucScore:.3f}')\n",
    "plt.plot([0,1],[0,1],'--', color='grey')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve (test)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Stepwise selection по AIC (stepAIC аналог)\n",
    "\n",
    "Реализуем простую stepwise selection для GLM (добавление/удаление по AIC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwiseSelectionGLM(dataFrame, response, candidatePredictors, family=sm.families.Binomial(), verbose=True):\n",
    "    included = []\n",
    "    while True:\n",
    "        changed = False\n",
    "        excluded = [p for p in candidatePredictors if p not in included]\n",
    "        bestAic = None\n",
    "        bestToAdd = None\n",
    "\n",
    "        for newCol in excluded:\n",
    "            tryPredictors = included + [newCol]\n",
    "            formulaTry = response + ' ~ ' + ' + '.join(tryPredictors) if tryPredictors else response + ' ~ 1'\n",
    "            modelTry = smf.glm(formula=formulaTry, data=dataFrame, family=family).fit()\n",
    "            if bestAic is None or modelTry.aic < bestAic:\n",
    "                bestAic = modelTry.aic\n",
    "                bestToAdd = newCol\n",
    "        \n",
    "        if bestToAdd is not None:\n",
    "            formulaCurrent = response + ' ~ ' + ' + '.join(included) if included else response + ' ~ 1'\n",
    "            modelCurrent = smf.glm(formula=formulaCurrent, data=dataFrame, family=family).fit()\n",
    "            if bestAic + 1e-8 < modelCurrent.aic:\n",
    "                included.append(bestToAdd)\n",
    "                changed = True\n",
    "                if verbose:\n",
    "                    print('Add', bestToAdd, 'AIC=', bestAic)\n",
    "\n",
    "        if included:\n",
    "            bestAic = None\n",
    "            worstToRemove = None\n",
    "            \n",
    "            for col in included:\n",
    "                tryPredictors = [c for c in included if c != col]\n",
    "                formulaTry = response + ' ~ ' + ' + '.join(tryPredictors) if tryPredictors else response + ' ~ 1'\n",
    "                modelTry = smf.glm(formula=formulaTry, data=dataFrame, family=family).fit()\n",
    "                if bestAic is None or modelTry.aic < bestAic:\n",
    "                    bestAic = modelTry.aic\n",
    "                    worstToRemove = col\n",
    "            \n",
    "            modelCurrent = smf.glm(formula=response + ' ~ ' + ' + '.join(included), data=dataFrame, family=family).fit()\n",
    "            if bestAic + 1e-8 < modelCurrent.aic:\n",
    "                included.remove(worstToRemove)\n",
    "                changed = True\n",
    "                if verbose:\n",
    "                    print('Remove', worstToRemove, 'improve AIC to', bestAic)\n",
    "        \n",
    "        if not changed:\n",
    "            break\n",
    "    \n",
    "    return included\n",
    "\n",
    "candidatePredictors = []\n",
    "for term in predictorTerms:\n",
    "    candidatePredictors.append(term)\n",
    "\n",
    "selectedPredictors = stepwiseSelectionGLM(doctorDataFrame, 'y', candidatePredictors, family=sm.families.Binomial(), verbose=True)\n",
    "print('\\nSelected predictors by stepwise AIC:', selectedPredictors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Повторный анализ (если stepwise дал другую модель)\n",
    "\n",
    "Если `selectedPredictors` отличается от исходных, подгоняем новую GLM и повторяем выводы/diagnostics (как выше): коэффициенты, CI, confusionMatrix, ROC и тесты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if set(selectedPredictors) != set(predictorTerms):\n",
    "    formulaImproved = 'y ~ ' + ' + '.join(selectedPredictors) if selectedPredictors else 'y ~ 1'\n",
    "    print('Fitting improved model formula:', formulaImproved)\n",
    "    glmImproved = smf.glm(formula=formulaImproved, data=doctorDataFrame, family=sm.families.Binomial()).fit()\n",
    "    print(glmImproved.summary())\n",
    "else:\n",
    "    print('Stepwise did not change predictors — оставляем базовую модель.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. VIF (мультиколлинеарность) — для числовых предикторов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vifDf = pd.DataFrame()\n",
    "numericPredictors = [c for c in ['x1','x2','x3','x5'] if c in doctorDataFrame.columns]\n",
    "\n",
    "dummiesX4 = pd.get_dummies(doctorDataFrame['x4_cat'], prefix='x4')\n",
    "vifX = pd.concat([doctorDataFrame[numericPredictors].reset_index(drop=True), dummiesX4.reset_index(drop=True)], axis=1)\n",
    "\n",
    "vifX = vifX.dropna()\n",
    "vifDf['feature'] = vifX.columns\n",
    "vifDf['VIF'] = [variance_inflation_factor(vifX.values, i) for i in range(vifX.shape[1])]\n",
    "print('VIF:')\n",
    "display(vifDf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
